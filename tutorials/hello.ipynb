{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello World\n",
    "\n",
    "Every framework has a hello world, Fugue is the same. But you must understand that distributed computing is not\n",
    "easy, being able to modify the hello world code for some simple things doesn't mean you master it. And please\n",
    "don't be misled by hello world examples of any distributed frameworks. There is much more to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import FugueWorkflow\n",
    "\n",
    "# create a dataframe and print\n",
    "with FugueWorkflow() as dag:\n",
    "    dag.df([[0,\"hello\"],[1,\"world\"]],\"x:int,b:str\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fugue is using DAG (Directed Acyclic Graph) to express workflow. You always construct a dag before executing it. Currently, Fugue does not support execution during construction (this is actually interactive mode). But the experience of using dag should be similar to using native Spark in notebook, both are lazy.\n",
    "\n",
    "The `with` statement tells the system I want to execute it when exiting. You don't have to use `with` all the time. For example, submitting to spark may be slow, it's totally fine we construct the dag, then start Spark and run it, this can capture many errors much quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import FugueWorkflow\n",
    "from fugue_spark import SparkExecutionEngine\n",
    "from fugue_dask import DaskExecutionEngine\n",
    "\n",
    "dag = FugueWorkflow()\n",
    "dag.df([[0,\"hello\"],[1,\"world\"]],\"x:int,b:str\").show()\n",
    "# here I have finished the construction, and the following is to run on different execution engines\n",
    "\n",
    "dag.run()                     # native python\n",
    "dag.run(SparkExecutionEngine) # spark\n",
    "dag.run(DaskExecutionEngine)  # dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find that the results are the same, but they are of different dataframes. Different execution engine will use different dataframes, they can convert to each other. Fugue tries to make the concept of `DataFrame` as abstract as possible, users in most cases only need to care data inside a dataframe.\n",
    "\n",
    "Here we show the simple ways to run the same dag on different execution engines, it's good for initial prototyping. But in real use cases, you should well configure your execution engines and then pass into the dag to run. Again, hello world `!=` real way to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
