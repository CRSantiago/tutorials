{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-like Objects\n",
    "\n",
    "In Fugue, it's flexibile to initialize many built-in objects. This is a tutorial for all of them.\n",
    "\n",
    "## Schema\n",
    "\n",
    "Fugue creates a special syntax to represent schema: Separated by `,`, each column type pair is `<name>:<type expression>`\n",
    "\n",
    "For example: `a:int,b:str` or `a:int,b_array:[int],c_dict:{x:int,y:str}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import Schema\n",
    "\n",
    "print(Schema(\"a:int,b:str\"))\n",
    "print(Schema(\"a:int32,b_array:[int64],c_dict:{x:int,y:string}\"))\n",
    "\n",
    "# get pyarrow schema\n",
    "schema = Schema(\" a : int , b : str\") # space is ok\n",
    "print(\"pa schema\", schema.pa_schema)\n",
    "\n",
    "# more ways to initialized fugue Schema\n",
    "print(Schema(schema.pa_schema)) # by pyarrow schema\n",
    "print(Schema(c=str,d=int)) # pythonic way\n",
    "print(Schema(dict(c=str,d=int))) # pythonic way\n",
    "print(Schema(\"e:str\",\"f:str\")) # you can separate\n",
    "print(Schema([\"e:str\",\"f:str\"], (\"g\",int))) # you can separate, notice int in python means long in schema\n",
    "print(Schema(Schema(\"a:int\",\"b:str\"))) # you can separate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "`ParamDict` is not that flexible, it can only accept dict or list of tuples just like python dict. `ParamDict` itself is a python dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triad.collections import ParamDict\n",
    "\n",
    "print(ParamDict())\n",
    "print(ParamDict(dict(a=1,b=\"d\")))\n",
    "print(ParamDict([(\"a\",1),(\"b\",\"d\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "Normally, you should create a dataframe from [ExecutionEngine](execution_engine.ipynb) or [FugueWorkflow](dag.ipynb). In general, all execution engines and workflows support list/iterable of python arrays and pandas or Fugue dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import ExecutionEngine, FugueWorkflow, NativeExecutionEngine, PandasDataFrame\n",
    "from fugue_dask import DaskExecutionEngine\n",
    "import pandas as pd\n",
    "\n",
    "def construct_df_by_execution_engine(eng:ExecutionEngine):\n",
    "    eng.to_df([[0]], \"a:int\", {\"x\":1}).show(title=\"from array\")\n",
    "    df = PandasDataFrame([[0]], \"a:int\")\n",
    "    eng.to_df(df).show(title=\"from fugue dataframe\")\n",
    "    eng.to_df(df.as_pandas()).show(title=\"from pandas dataframe\")\n",
    "    \n",
    "construct_df_by_execution_engine(NativeExecutionEngine())\n",
    "construct_df_by_execution_engine(DaskExecutionEngine())  # notice the dataframe types change\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "def construct_df_by_workflow(eng:ExecutionEngine):\n",
    "    with FugueWorkflow(eng) as dag:\n",
    "        dag.df([[0]], \"a:int\", {\"x\":1}).show(title=\"from array\")\n",
    "        df = PandasDataFrame([[0]], \"a:int\")\n",
    "        dag.df(df).show(title=\"from fugue dataframe\")\n",
    "        dag.df(df.as_pandas()).show(title=\"from pandas dataframe\")\n",
    "        \n",
    "construct_df_by_workflow(NativeExecutionEngine())\n",
    "construct_df_by_workflow(DaskExecutionEngine())  # notice the dataframe types change   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fugue import PartitionSpec\n",
    "\n",
    "assert PartitionSpec().empty # empty partition spec means no operation needed, it can be the default value\n",
    "PartitionSpec(num=4)\n",
    "PartitionSpec(algo=\"even\",num=4,by=[\"a\",\"b\"],presort=\"c,d desc\") # c,d desc == c ASC, d DESC\n",
    "\n",
    "# you can use expression in num, ROWCOUNT can be used to indicate using the row count of the dataframe to operate on\n",
    "# if a df has 1000 rows, this means I want to even partition it to 10 rows per partition\n",
    "PartitionSpec(algo=\"even\",num=\"ROWCOUNT/10\")\n",
    "\n",
    "PartitionSpec({\"num\":4, \"by\":[\"a\",\"b\"]}) # from dict, using dict on `partition-like`  parameters is common\n",
    "PartitionSpec('{\"num\":4}') # from json\n",
    "\n",
    "a = PartitionSpec(num=4)\n",
    "b = PartitionSpec(by=[\"a\"])\n",
    "c = PartitionSpec(a,b) # combine\n",
    "\n",
    "p = PartitionSpec(num=4, by=[\"a\"])\n",
    "PartitionSpec(p, by=[\"a\",\"b\"], algo=\"even\") # override"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
