{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('fugue-tutorials': conda)",
   "metadata": {
    "interpreter": {
     "hash": "131b24c7e1bb8763ab2b04d5b6d98a68c7b3a823a2a57c5722935f7690890f70"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Using databricks-connect\n",
    "\n",
    "A lot of Databricks users use the `databricks-connect` library to execute Spark commands on a Databricks cluster instead of a local session. `databricks-connect` replaces the local installation of `pyspark` and makes `pyspark` code get executed on the cluster, allowing users to use the cluster directly from their IDE. \n",
    "\n",
    "For more information check the [Databricks](https://docs.databricks.com/dev-tools/databricks-connect.html) or [Azure](https://docs.microsoft.com/en-us/azure/databricks/dev-tools/databricks-connect) documentation for how to configure `databricks-connect`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Difficulty of Testing\n",
    "\n",
    "While `databricks-connect` is convenient for leveraging cluster compute resources, it also makes it difficult to conduct tests quickly. Spinning up a cluster takes around 3-4 minutes, slowing down iterations. Development also becomes very expensive as the `databricks-connect` configuration is attached to a cluster, meaning that it's inconvenient to switch to a smaller cluster for smaller tests.\n",
    "\n",
    "This whole process is costly in most developer time with slow iterations, and with cluster costs, having to spin up everytime."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fugue and databricks-connect\n",
    "\n",
    "Fugue helps solve this problem by allowing users to use the default `NativeExecutionEngine` for local development and testing. Users can use sampled files for local development, and then bring it to Spark when ready for larger tests. To demo this, we have a sample code snippet below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PandasDataFrame\nnumbers:long|words:str|reversed:str\n------------+---------+------------\n1           |hello    |olleh       \n2           |world    |dlrow       \n3           |apple    |elppa       \n4           |banana   |ananab      \nTotal count: 4\n\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fugue import FugueWorkflow\n",
    "from fugue_spark import SparkExecutionEngine\n",
    "\n",
    "data = pd.DataFrame({'numbers':[1,2,3,4], 'words':['hello','world','apple','banana']})\n",
    "\n",
    "# schema: *, reversed:str\n",
    "def reverse_word(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['reversed'] = df['words'].apply(lambda x: x[::-1])\n",
    "    return df\n",
    "\n",
    "with FugueWorkflow() as dag:\n",
    "    df = dag.df(data)\n",
    "    df = df.transform(reverse_word)\n",
    "    df.show()"
   ]
  },
  {
   "source": [
    "Again, this DataFrame is just 4 rows, but we should need to bring it to the Spark cluster if we were using `databricks-connect`. Here, we perform the test locally first and confirm that it works. After that, we can bring it to Spark with:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SparkDataFrame\nnumbers:long|words:str|reversed:str\n------------+---------+------------\n1           |hello    |olleh       \n2           |world    |dlrow       \n3           |apple    |elppa       \n4           |banana   |ananab      \nTotal count: 4\n\n"
     ]
    }
   ],
   "source": [
    "# This Pandas DataFrame gets converted to Spark\n",
    "data = pd.DataFrame({'numbers':[1,2,3,4], 'words':['hello','world','apple','banana']})\n",
    "\n",
    "with FugueWorkflow(SparkExecutionEngine) as dag:\n",
    "    df = dag.df(data)\n",
    "    df = df.transform(reverse_word)\n",
    "    df.show()"
   ]
  },
  {
   "source": [
    "No added work is needed. The `SparkExecutionEngine` imports `pyspark`, meaning that it will import the `databricks-connect` configuration under the hood and use the configured cluster. Fugue works with `databricks-connect` seamlessly, allowing for convenient switching between local development and a remote cluster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Added Configuration\n",
    "\n",
    "Most `databricks-connect` users add additional Spark configurations on the cluster. If additional configruation is needed in local code, it can be provided with the following syntax:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from fugue_spark import SparkExecutionEngine\n",
    "\n",
    "spark_session = (SparkSession\n",
    "                 .builder\n",
    "                 .config(\"spark.executor.cores\",4)\n",
    "                 .config(\"fugue.dummy\",\"dummy\")\n",
    "                 .getOrCreate())\n",
    "\n",
    "engine = SparkExecutionEngine(spark_session, {\"additional_conf\":\"abc\"})"
   ]
  },
  {
   "source": [
    "## Using Fugue-sql on the Cluster\n",
    "\n",
    "Because Fugue-sql also just uses the `SparkExecutionEngine`, it can also be easily executed on a remote cluster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "spark is not a type",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/triad/utils/convert.py\u001b[0m in \u001b[0;36mstr_to_object\u001b[0;34m(expr, global_vars, local_vars)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_globals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_locals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/execution/factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/triad/utils/convert.py\u001b[0m in \u001b[0;36mstr_to_type\u001b[0;34m(s, expected_base_type, global_vars, local_vars)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_to_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/triad/utils/convert.py\u001b[0m in \u001b[0;36mstr_to_object\u001b[0;34m(expr, global_vars, local_vars)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: spark",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f06dead547eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'numbers'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'words'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'world'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'apple'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'banana'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m fsql(\"\"\"\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mSELECT\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mFROM\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/workflow/workflow.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workflow_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workflow_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_computed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/workflow/workflow.py\u001b[0m in \u001b[0;36m_to_ctx\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFugueWorkflowContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1884\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mFugueWorkflowContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_execution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/execution/factory.py\u001b[0m in \u001b[0;36mmake_execution_engine\u001b[0;34m(engine, conf, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mmake_execution_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparkExecutionEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_EXECUTION_ENGINE_FACTORY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/execution/factory.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, engine, conf, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     def make_execution_engine(\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/execution/factory.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, engine, conf, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     ) -> ExecutionEngine:\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             execution_engine = self.make_execution_engine(\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mengine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             )\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/fugue/execution/factory.py\u001b[0m in \u001b[0;36mmake_execution_engine\u001b[0;34m(self, engine, conf, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             )\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExecutionEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     def make_sql_engine(\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/triad/utils/convert.py\u001b[0m in \u001b[0;36mto_instance\u001b[0;34m(s, expected_base_type, args, kwargs, global_vars, local_vars)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None can't be converted to instance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_base_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/triad/utils/convert.py\u001b[0m in \u001b[0;36mto_type\u001b[0;34m(s, expected_base_type, global_vars, local_vars)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mglobal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_caller_global_local_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr_to_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_base_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpected_base_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_base_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/fugue-tutorials/lib/python3.8/site-packages/triad/utils/convert.py\u001b[0m in \u001b[0;36mstr_to_type\u001b[0;34m(s, expected_base_type, global_vars, local_vars)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_to_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{s} is not a type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0massert_or_throw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{obj} is not a type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     assert_or_throw(\n",
      "\u001b[0;31mTypeError\u001b[0m: spark is not a type"
     ]
    }
   ],
   "source": [
    "from fugue_sql import fsql\n",
    "\n",
    "data = pd.DataFrame({'numbers':[1,2,3,4], 'words':['hello','world','apple','banana']})\n",
    "\n",
    "fsql(\"\"\"\n",
    "      SELECT *\n",
    "        FROM data\n",
    "      TRANSFORM USING reverse_word\"\"\"\n",
    ").run(SparkExecutionEngine)"
   ]
  },
  {
   "source": [
    "## Conclusion\n",
    "\n",
    "Here we have shown the painpoints in using `databricks-connect`. It slows down developer productitity and increases compute costs. We can solve both of these problems by toggling between Fugue's default `NativeExecutionEngine` and `SparkExecutionEngine`. Fugue's `SparkExecutionEngine` will seamlessly use whatever `pyspark` is configured for the user.\n",
    "\n",
    "Fugue also allows for additional configuration of the underlying frameworks. We showed the syntax for passing a `SparkSession` to the `SparkExecutionEngine`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}